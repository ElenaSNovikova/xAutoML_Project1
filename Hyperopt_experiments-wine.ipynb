{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hyperopt\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 6.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting py4j\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "\u001b[K     |████████████████████████████████| 200 kB 31.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: future in /Users/luzanikita/Software/anaconda3/lib/python3.8/site-packages (from hyperopt) (0.18.2)\n",
      "Requirement already satisfied: tqdm in /Users/luzanikita/Software/anaconda3/lib/python3.8/site-packages (from hyperopt) (4.47.0)\n",
      "Requirement already satisfied: cloudpickle in /Users/luzanikita/Software/anaconda3/lib/python3.8/site-packages (from hyperopt) (1.5.0)\n",
      "Requirement already satisfied: scipy in /Users/luzanikita/Software/anaconda3/lib/python3.8/site-packages (from hyperopt) (1.5.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /Users/luzanikita/Software/anaconda3/lib/python3.8/site-packages (from hyperopt) (2.4)\n",
      "Requirement already satisfied: six in /Users/luzanikita/Software/anaconda3/lib/python3.8/site-packages (from hyperopt) (1.15.0)\n",
      "Requirement already satisfied: numpy in /Users/luzanikita/Software/anaconda3/lib/python3.8/site-packages (from hyperopt) (1.19.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/luzanikita/Software/anaconda3/lib/python3.8/site-packages (from networkx>=2.2->hyperopt) (4.4.2)\n",
      "Installing collected packages: py4j, hyperopt\n",
      "Successfully installed hyperopt-0.2.7 py4j-0.10.9.7\n"
     ]
    }
   ],
   "source": [
    "! pip3 install  hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
    "RANDOM_SEED: int = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading train/test datasets and results df\n",
    "results_df_path = 'model_cmp.csv'\n",
    "df = pd.read_csv('data/winequality-red.csv')\n",
    "X, y = df.drop('quality', axis=1), df.quality > 5\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=RANDOM_SEED, test_size=.2, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8259587020648967"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_baseline = RandomForestClassifier(n_jobs=-1).fit(X_train, y_train)\n",
    "y_pred_baseline = clf_baseline.predict(X_test)\n",
    "f1_baseline = f1_score(y_test, y_pred_baseline)\n",
    "f1_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_cv(params):\n",
    "    f1_scores = []\n",
    "    for train_index, test_index in skf.split(X_train, y_train):\n",
    "        X_train_cv, X_val = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_cv, y_val = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        model = ExtraTreesClassifier(random_state=42, n_jobs=-1, **params).fit(X_train_cv, y_train_cv)\n",
    "        score = f1_score(y_val, model.predict(X_val))\n",
    "        f1_scores.append(score)\n",
    "    return {'loss': -np.mean(f1_scores), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_fast(params):\n",
    "    X_train_cv, X_val, y_train_cv, y_val =  train_test_split(X_train, y_train, test_size=.2, random_state=RANDOM_SEED)\n",
    "    model = ExtraTreesClassifier(random_state=42, n_jobs=-1, **params).fit(X_train_cv, y_train_cv)\n",
    "    score = f1_score(y_val, model.predict(X_val))\n",
    "    return {'loss': -score, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(search_space, budget:int = 10, use_cv: bool =True, method: str = 'random') -> float:\n",
    "    if use_cv:\n",
    "        objective = objective_cv\n",
    "    else:\n",
    "        objective = objective_fast\n",
    "    \n",
    "    if method == 'random':\n",
    "        method = rand.suggest\n",
    "    elif method == 'tpe':\n",
    "        method = tpe.suggest\n",
    "    \n",
    "    best_params = fmin(\n",
    "        fn=objective,\n",
    "        space=search_space,\n",
    "        algo=method,\n",
    "        max_evals=budget)\n",
    "    \n",
    "    return space_eval(search_space, best_params), objective(space_eval(search_space, best_params))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space={\n",
    "    'max_depth': hp.randint('max_depth', 1, 200),           \n",
    "    'min_samples_split':hp.randint('min_samples_split', 2, 5),   \n",
    "    'min_samples_leaf':hp.randint('min_samples_leaf', 1, 20),\n",
    "    'criterion':hp.choice('criterion', ['gini', 'entropy']),\n",
    "    'max_features':hp.choice('max_features', ['sqrt', 'log2', 0.9]),\n",
    "    'bootstrap':hp.choice('bootstrap', [True, False]),\n",
    "    \"class_weight\": hp.choice('class_weight', ['balanced', 'balanced_subsample'])\n",
    "}\n",
    "algorithm=tpe.suggest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.36trial/s, best loss: -0.8112449799196787]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'class_weight': 'balanced',\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 22,\n",
       " 'max_features': 0.9,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 4}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params, _ = run_experiment(search_space, 5, use_cv=False, method='tpe')\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7926829268292682"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = ExtraTreesClassifier(**params, random_state=42, n_jobs=-1).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optmimize(\n",
    "    datasets, f1_baseline, budget_list, opt_method_list,\n",
    "    use_cv=True, early_stopping=True\n",
    "):\n",
    "    X_train, X_test, y_train, y_test = datasets\n",
    "    final_params = {}\n",
    "    final_scores = {}\n",
    "    try:\n",
    "        for budget in budget_list:\n",
    "            for opt_method in opt_method_list:\n",
    "                print((budget, opt_method))\n",
    "                # tune model\n",
    "                params, _ = run_experiment(search_space, budget, use_cv=use_cv, method=opt_method)\n",
    "                final_params[(budget, opt_method)] = params\n",
    "\n",
    "                # evaluate model\n",
    "                clf = ExtraTreesClassifier(random_state=42, **params, n_jobs=-1).fit(X_train, y_train)\n",
    "                y_pred_opt = clf.predict(X_test)\n",
    "                f1 = f1_score(y_test, y_pred_opt)\n",
    "                final_scores[(budget, opt_method)] = f1\n",
    "                print(f\"F1-score: {f1}\")\n",
    "\n",
    "                # early stopping condition, because we are looking for the smallest time budget\n",
    "                if early_stopping and f1 > f1_baseline:\n",
    "                    A = ((y_pred_baseline == y_test) & (y_pred_opt == y_test)).sum()\n",
    "                    B = ((y_pred_baseline != y_test) & (y_pred_opt == y_test)).sum()\n",
    "                    C = ((y_pred_baseline == y_test) & (y_pred_opt != y_test)).sum()\n",
    "                    D = ((y_pred_baseline != y_test) & (y_pred_opt != y_test)).sum()\n",
    "                    result = mcnemar([[A, B], [C, D]])\n",
    "                    alpha = 0.05\n",
    "                    if B + C > 20 and result.pvalue < alpha:\n",
    "                        print(f\"Model with time budget {budget} and {opt_method} optimization algo beat the baseline!\")\n",
    "                        return (budget, opt_method), final_params, final_scores\n",
    "                    else:\n",
    "                        print(\"F1 is better, but not statistically\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted.\")\n",
    "        \n",
    "    print(\"No model outperformed the baseline\")\n",
    "    return None, final_params, final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_params = {}\n",
    "final_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 'tpe')\n",
      "100%|██████████| 10/10 [00:17<00:00,  1.76s/trial, best loss: -0.8161467853296603]\n",
      "F1-score: 0.8036253776435045\n",
      "(20, 'tpe')\n",
      "100%|██████████| 20/20 [00:23<00:00,  1.16s/trial, best loss: -0.8164002509750485]\n",
      "F1-score: 0.8221574344023324\n",
      "(50, 'tpe')\n",
      "100%|██████████| 50/50 [01:24<00:00,  1.70s/trial, best loss: -0.81801586794]     \n",
      "F1-score: 0.8214285714285714\n",
      "(100, 'tpe')\n",
      "100%|██████████| 100/100 [02:55<00:00,  1.75s/trial, best loss: -0.8215628574225663]\n",
      "F1-score: 0.8168168168168167\n",
      "(200, 'tpe')\n",
      "100%|██████████| 200/200 [05:36<00:00,  1.68s/trial, best loss: -0.82216029844896] \n",
      "F1-score: 0.8132530120481928\n",
      "(500, 'tpe')\n",
      " 26%|██▌       | 130/500 [03:52<11:00,  1.79s/trial, best loss: -0.8251873077524987]\n",
      "Interrupted.\n",
      "No model outperformed the baseline\n"
     ]
    }
   ],
   "source": [
    "datasets = X_train, X_test, y_train, y_test\n",
    "best, params, scores = optmimize(\n",
    "    datasets, f1_baseline, budget_list=[10, 20, 50, 100, 200, 500, 1000, 2000, 5000, 10000], \n",
    "    opt_method_list=['tpe'], use_cv=True)\n",
    "final_params.update(params)\n",
    "final_scores.update(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 'random')\n",
      "100%|██████████| 10/10 [00:18<00:00,  1.80s/trial, best loss: -0.82168574877736] \n",
      "F1-score: 0.8367952522255192\n",
      "F1 is better, but not statistically\n",
      "(20, 'random')\n",
      "100%|██████████| 20/20 [00:39<00:00,  1.97s/trial, best loss: -0.8197646891820621]\n",
      "F1-score: 0.8143712574850298\n",
      "(50, 'random')\n",
      "100%|██████████| 50/50 [01:30<00:00,  1.80s/trial, best loss: -0.81801586794]     \n",
      "F1-score: 0.8214285714285714\n",
      "(100, 'random')\n",
      "100%|██████████| 100/100 [02:57<00:00,  1.77s/trial, best loss: -0.8251873077524987]\n",
      "F1-score: 0.8245614035087719\n",
      "(200, 'random')\n",
      "100%|██████████| 200/200 [06:20<00:00,  1.90s/trial, best loss: -0.8251873077524987]\n",
      "F1-score: 0.8245614035087719\n",
      "(500, 'random')\n",
      "100%|██████████| 500/500 [16:16<00:00,  1.95s/trial, best loss: -0.82168574877736]  \n",
      "F1-score: 0.8367952522255192\n",
      "F1 is better, but not statistically\n",
      "(1000, 'random')\n",
      "  1%|          | 10/1000 [00:20<34:38,  2.10s/trial, best loss: -0.8251873077524987]\n",
      "Interrupted.\n",
      "No model outperformed the baseline\n"
     ]
    }
   ],
   "source": [
    "datasets = X_train, X_test, y_train, y_test\n",
    "best, params, scores = optmimize(\n",
    "    datasets, f1_baseline, budget_list=[10, 20, 50, 100, 200, 500, 1000, 2000, 5000, 10000], \n",
    "    opt_method_list=['random'], use_cv=True)\n",
    "final_params.update(params)\n",
    "final_scores.update(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space.update({\"n_estimators\": hp.randint('n_estimators', 50, 200)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 'random')\n",
      "100%|██████████| 1000/1000 [40:14<00:00,  2.41s/trial, best loss: -0.8257992774739824]\n",
      "F1-score: 0.8259587020648967\n",
      "(2000, 'random')\n",
      "100%|██████████| 2000/2000 [1:15:38<00:00,  2.27s/trial, best loss: -0.8277212997419445]\n",
      "F1-score: 0.813953488372093\n",
      "(5000, 'random')\n",
      "100%|██████████| 5000/5000 [3:03:21<00:00,  2.20s/trial, best loss: -0.8319567569242489]  \n",
      "F1-score: 0.8224852071005917\n",
      "(10000, 'random')\n",
      " 38%|███▊      | 3846/10000 [2:24:06<3:50:35,  2.25s/trial, best loss: -0.8281653094223579]\n",
      "Interrupted.\n",
      "No model outperformed the baseline\n"
     ]
    }
   ],
   "source": [
    "datasets = X_train, X_test, y_train, y_test\n",
    "best, params, scores = optmimize(\n",
    "    datasets, f1_baseline, budget_list=[1000, 2000, 5000, 10000], \n",
    "    opt_method_list=['random'], use_cv=True)\n",
    "final_params.update(params)\n",
    "final_scores.update(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({(10, 'tpe'): {'bootstrap': True,\n",
       "   'class_weight': 'balanced',\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 182,\n",
       "   'max_features': 0.9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4},\n",
       "  (20, 'tpe'): {'bootstrap': False,\n",
       "   'class_weight': 'balanced_subsample',\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 150,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 3},\n",
       "  (50, 'tpe'): {'bootstrap': False,\n",
       "   'class_weight': 'balanced',\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 94,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 4},\n",
       "  (100, 'tpe'): {'bootstrap': False,\n",
       "   'class_weight': 'balanced_subsample',\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 63,\n",
       "   'max_features': 0.9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3},\n",
       "  (200, 'tpe'): {'bootstrap': False,\n",
       "   'class_weight': 'balanced',\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4},\n",
       "  (10, 'random'): {'bootstrap': False,\n",
       "   'class_weight': 'balanced',\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 55,\n",
       "   'max_features': 0.9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2},\n",
       "  (20, 'random'): {'bootstrap': False,\n",
       "   'class_weight': 'balanced_subsample',\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 21,\n",
       "   'max_features': 0.9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2},\n",
       "  (50, 'random'): {'bootstrap': False,\n",
       "   'class_weight': 'balanced',\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 59,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 4},\n",
       "  (100, 'random'): {'bootstrap': False,\n",
       "   'class_weight': 'balanced_subsample',\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 120,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2},\n",
       "  (200, 'random'): {'bootstrap': False,\n",
       "   'class_weight': 'balanced_subsample',\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 161,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2},\n",
       "  (500, 'random'): {'bootstrap': False,\n",
       "   'class_weight': 'balanced_subsample',\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 41,\n",
       "   'max_features': 0.9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2},\n",
       "  (1000, 'tpe'): {'bootstrap': True,\n",
       "   'class_weight': 'balanced',\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 106,\n",
       "   'max_features': 0.9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 50},\n",
       "  (1000, 'random'): {'bootstrap': False,\n",
       "   'class_weight': 'balanced_subsample',\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 63,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 65},\n",
       "  (2000, 'random'): {'bootstrap': False,\n",
       "   'class_weight': 'balanced',\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 199,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 59},\n",
       "  (5000, 'random'): {'bootstrap': True,\n",
       "   'class_weight': 'balanced',\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 40,\n",
       "   'max_features': 0.9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 72}},\n",
       " {(10, 'tpe'): 0.8036253776435045,\n",
       "  (20, 'tpe'): 0.8221574344023324,\n",
       "  (50, 'tpe'): 0.8214285714285714,\n",
       "  (100, 'tpe'): 0.8168168168168167,\n",
       "  (200, 'tpe'): 0.8132530120481928,\n",
       "  (10, 'random'): 0.8367952522255192,\n",
       "  (20, 'random'): 0.8143712574850298,\n",
       "  (50, 'random'): 0.8214285714285714,\n",
       "  (100, 'random'): 0.8245614035087719,\n",
       "  (200, 'random'): 0.8245614035087719,\n",
       "  (500, 'random'): 0.8367952522255192,\n",
       "  (1000, 'tpe'): 0.8298507462686566,\n",
       "  (1000, 'random'): 0.8259587020648967,\n",
       "  (2000, 'random'): 0.813953488372093,\n",
       "  (5000, 'random'): 0.8224852071005917})"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_params, final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8367952522255192"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = final_params[(10, 'random')]\n",
    "\n",
    "clf = ExtraTreesClassifier(**params, random_state=42, n_jobs=-1).fit(X_train, y_train)\n",
    "y_pred_opt = clf.predict(X_test)\n",
    "metric = f1_score(y_test, y_pred_opt)\n",
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8259587020648967"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.contingency_tables import mcnemar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nr_correct_clf1</th>\n",
       "      <th>nr_incorrect_cl1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nr_correct_clf2</th>\n",
       "      <td>253</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nr_incorrect_clf2</th>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  nr_correct_clf1 nr_incorrect_cl1\n",
       "nr_correct_clf2               253               12\n",
       "nr_incorrect_clf2               8               47"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = ((y_pred_baseline == y_test) & (y_pred_opt == y_test)).sum()\n",
    "B = ((y_pred_baseline != y_test) & (y_pred_opt == y_test)).sum()\n",
    "C = ((y_pred_baseline == y_test) & (y_pred_opt != y_test)).sum()\n",
    "D = ((y_pred_baseline != y_test) & (y_pred_opt != y_test)).sum()\n",
    "\n",
    "contingency_table_df=pd.DataFrame(data={\"nr_correct_clf1\":[\"Yes/Yes\",\"No/Yes\"], \"nr_incorrect_cl1\":[\"Yes/No\",\"No/No\"]}, index=[\"nr_correct_clf2\",\"nr_incorrect_clf2\"])\n",
    "contingency_table_df.iloc[0,0]=A\n",
    "contingency_table_df.iloc[0,1]=B\n",
    "contingency_table_df.iloc[1,0]=C\n",
    "contingency_table_df.iloc[1,1]=D\n",
    "contingency_table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B + C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After calculating the Contingency Table, we need to define your hypothesis:\n",
    "*   H0: both models have the same performance\n",
    "*   H1: performances of the two models are not equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pvalue      0.5034446716308595\n",
      "statistic   8.0\n",
      "Same proportions of errors (fail to reject H0)\n"
     ]
    }
   ],
   "source": [
    "result = mcnemar([[A, B], [C, D]])\n",
    "print(result)\n",
    "alpha = 0.05\n",
    "if result.pvalue > alpha:\n",
    "    print('Same proportions of errors (fail to reject H0)')\n",
    "else:\n",
    "    print('Different proportions of errors (reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets compare on crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00,  6.48it/s]\n",
      "3it [00:00,  6.96it/s]\n",
      "3it [00:00,  6.81it/s]\n",
      "3it [00:00,  6.28it/s]\n",
      "3it [00:00,  6.07it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "params_list = [final_params[(10, 'random')], final_params[(500, 'random')], {}]\n",
    "N_FOLDS: int = 5\n",
    "    \n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "results = np.zeros((len(params_list), N_FOLDS))\n",
    "cur_fold = 0\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train_cv, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train_cv, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    for i, params in tqdm(enumerate(params_list)):\n",
    "        clf = ExtraTreesClassifier(**params, random_state=42, n_jobs=-1).fit(X_train_cv, y_train_cv)\n",
    "        score = f1_score(y_val, clf.predict(X_val))\n",
    "        results[i, cur_fold] = score\n",
    "    cur_fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FriedmanchisquareResult(statistic=10.0, pvalue=0.006737946999085468)\n",
      "Different distributions (reject H0)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import friedmanchisquare\n",
    "\n",
    "result = friedmanchisquare(*results.tolist())\n",
    "print(result)\n",
    "\n",
    "p = result.pvalue\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distributions (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.848837</td>\n",
       "      <td>0.819767</td>\n",
       "      <td>0.861878</td>\n",
       "      <td>0.782090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.848837</td>\n",
       "      <td>0.819767</td>\n",
       "      <td>0.861878</td>\n",
       "      <td>0.782090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.809249</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.815476</td>\n",
       "      <td>0.856354</td>\n",
       "      <td>0.752294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4\n",
       "0  0.816327  0.848837  0.819767  0.861878  0.782090\n",
       "1  0.816327  0.848837  0.819767  0.861878  0.782090\n",
       "2  0.809249  0.842105  0.815476  0.856354  0.752294"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>r3</th>\n",
       "      <th>r4</th>\n",
       "      <th>r5</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    r1   r2   r3   r4   r5  mean\n",
       "0  1.5  1.5  1.5  1.5  1.5   1.5\n",
       "1  1.5  1.5  1.5  1.5  1.5   1.5\n",
       "2  3.0  3.0  3.0  3.0  3.0   3.0"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks = pd.DataFrame()\n",
    "ranks['r1'] = results.loc[:, 0].rank(ascending=False)\n",
    "ranks['r2'] = results.loc[:, 1].rank(ascending=False)\n",
    "ranks['r3'] = results.loc[:, 2].rank(ascending=False)\n",
    "ranks['r4'] = results.loc[:, 3].rank(ascending=False)\n",
    "ranks['r5'] = results.loc[:, 4].rank(ascending=False)\n",
    "ranks['mean'] = ranks.mean(axis=1)\n",
    "ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see first two configurations are better than the third one (baseline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'bootstrap': False,\n",
       "  'class_weight': 'balanced',\n",
       "  'criterion': 'entropy',\n",
       "  'max_depth': 55,\n",
       "  'max_features': 0.9,\n",
       "  'min_samples_leaf': 1,\n",
       "  'min_samples_split': 2},\n",
       " {'bootstrap': False,\n",
       "  'class_weight': 'balanced_subsample',\n",
       "  'criterion': 'entropy',\n",
       "  'max_depth': 41,\n",
       "  'max_features': 0.9,\n",
       "  'min_samples_leaf': 1,\n",
       "  'min_samples_split': 2})"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_params[(10, 'random')], final_params[(500, 'random')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
