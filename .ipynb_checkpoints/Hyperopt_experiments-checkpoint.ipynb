{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hyperopt\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 6.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting py4j\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "\u001b[K     |████████████████████████████████| 200 kB 31.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: future in /Users/luzanikita/Software/anaconda3/lib/python3.8/site-packages (from hyperopt) (0.18.2)\n",
      "Requirement already satisfied: tqdm in /Users/luzanikita/Software/anaconda3/lib/python3.8/site-packages (from hyperopt) (4.47.0)\n",
      "Requirement already satisfied: cloudpickle in /Users/luzanikita/Software/anaconda3/lib/python3.8/site-packages (from hyperopt) (1.5.0)\n",
      "Requirement already satisfied: scipy in /Users/luzanikita/Software/anaconda3/lib/python3.8/site-packages (from hyperopt) (1.5.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /Users/luzanikita/Software/anaconda3/lib/python3.8/site-packages (from hyperopt) (2.4)\n",
      "Requirement already satisfied: six in /Users/luzanikita/Software/anaconda3/lib/python3.8/site-packages (from hyperopt) (1.15.0)\n",
      "Requirement already satisfied: numpy in /Users/luzanikita/Software/anaconda3/lib/python3.8/site-packages (from hyperopt) (1.19.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/luzanikita/Software/anaconda3/lib/python3.8/site-packages (from networkx>=2.2->hyperopt) (4.4.2)\n",
      "Installing collected packages: py4j, hyperopt\n",
      "Successfully installed hyperopt-0.2.7 py4j-0.10.9.7\n"
     ]
    }
   ],
   "source": [
    "! pip3 install  hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
    "RANDOM_SEED: int = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading train/test datasets and results df\n",
    "results_df_path = 'model_cmp.csv'\n",
    "df = pd.read_csv('data/creditcard.csv')\n",
    "X,y = df.drop('Class', axis=1), df.Class\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=RANDOM_SEED, test_size=.2, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8913043478260869"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_baseline = ExtraTreesClassifier(n_jobs=-1).fit(X_train, y_train)\n",
    "y_pred_baseline = clf_baseline.predict(X_test)\n",
    "f1_baseline = f1_score(y_test, y_pred_baseline)\n",
    "f1_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_cv(params):\n",
    "    f1_scores = []\n",
    "    for train_index, test_index in skf.split(X_train, y_train):\n",
    "        X_train_cv, X_val = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_cv, y_val = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        model = ExtraTreesClassifier(random_state=42, n_jobs=-1, **params).fit(X_train_cv, y_train_cv)\n",
    "        score = f1_score(y_val, model.predict(X_val))\n",
    "        f1_scores.append(score)\n",
    "    return {'loss': -np.mean(f1_scores), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_fast(params):\n",
    "    X_train_cv, X_val, y_train_cv, y_val =  train_test_split(X_train, y_train, test_size=.2, random_state=RANDOM_SEED)\n",
    "    model = ExtraTreesClassifier(random_state=42, n_jobs=-1, **params).fit(X_train_cv, y_train_cv)\n",
    "    score = f1_score(y_val, model.predict(X_val))\n",
    "    return {'loss': -score, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(search_space, budget:int = 10, use_cv: bool =True, method: str = 'random') -> float:\n",
    "    if use_cv:\n",
    "        objective = objective_cv\n",
    "    else:\n",
    "        objective = objective_fast\n",
    "    \n",
    "    if method == 'random':\n",
    "        method = rand.suggest\n",
    "    elif method == 'tpe':\n",
    "        method = tpe.suggest\n",
    "    \n",
    "    best_params = fmin(\n",
    "        fn=objective,\n",
    "        space=search_space,\n",
    "        algo=method,\n",
    "        max_evals=budget)\n",
    "    \n",
    "    return space_eval(search_space, best_params), objective(space_eval(search_space, best_params))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space={\n",
    "    'max_depth': hp.randint('max_depth', 1, 200),           \n",
    "    'min_samples_split':hp.randint('min_samples_split', 2, 5),   \n",
    "    'min_samples_leaf':hp.randint('min_samples_leaf', 1, 20),\n",
    "    'criterion':hp.choice('criterion', ['gini', 'entropy']),\n",
    "    'max_features':hp.choice('max_features', ['sqrt', 'log2', 0.9]),\n",
    "    'bootstrap':hp.choice('bootstrap', [True, False]),\n",
    "    \"class_weight\": hp.choice('class_weight', ['balanced', 'balanced_subsample'])\n",
    "}\n",
    "algorithm=tpe.suggest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:18<00:00,  3.68s/trial, best loss: -0.75]              \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': 191,\n",
       " 'max_features': 0.9,\n",
       " 'min_samples_leaf': 19,\n",
       " 'min_samples_split': 3}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params, _ = run_experiment(search_space, 5, use_cv=False, method='tpe')\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8148148148148148"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = ExtraTreesClassifier(**params, random_state=42, n_jobs=-1).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optmimize(datasets, f1_baseline, budget_list, opt_method_list, use_cv=True, early_stopping=True):\n",
    "    X_train, X_test, y_train, y_test = datasets\n",
    "    final_params = {}\n",
    "    final_scores = {}\n",
    "    try:\n",
    "        for budget in budget_list:\n",
    "            for opt_method in opt_method_list:\n",
    "                print((budget, opt_method))\n",
    "                # tune model\n",
    "                params, _ = run_experiment(search_space, budget, use_cv=use_cv, method=opt_method)\n",
    "                final_params[(budget, opt_method)] = params\n",
    "\n",
    "                # evaluate model\n",
    "                clf = ExtraTreesClassifier(random_state=42, **params, n_jobs=-1).fit(X_train, y_train)\n",
    "                y_pred_opt = clf.predict(X_test)\n",
    "                f1 = f1_score(y_test, y_pred_opt)\n",
    "                final_scores[(budget, opt_method)] = f1\n",
    "                print(f\"F1-score: {f1}\")\n",
    "\n",
    "                # early stopping condition, because we are looking for the smallest time budget\n",
    "                if early_stopping and f1 > f1_baseline:\n",
    "                    A = ((y_pred_baseline == y_test) & (y_pred_opt == y_test)).sum()\n",
    "                    B = ((y_pred_baseline != y_test) & (y_pred_opt == y_test)).sum()\n",
    "                    C = ((y_pred_baseline == y_test) & (y_pred_opt != y_test)).sum()\n",
    "                    D = ((y_pred_baseline != y_test) & (y_pred_opt != y_test)).sum()\n",
    "                    result = mcnemar([[A, B], [C, D]])\n",
    "                    alpha = 0.05\n",
    "                    if B + C > 20 and result.pvalue < alpha:\n",
    "                        print(f\"Model with time budget {budget} and {opt_method} optimization algo beat the baseline!\")\n",
    "                        return (budget, opt_method), final_params, final_scores\n",
    "                    else:\n",
    "                        print(\"F1 is better, but not statistically\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted.\")\n",
    "        \n",
    "    print(\"No model outperformed the baseline\")\n",
    "    return None, final_params, final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_params = {}\n",
    "final_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 'tpe')\n",
      "100%|██████████| 10/10 [00:55<00:00,  5.55s/trial, best loss: -0.7681159420289856]\n",
      "F1-score: 0.8431372549019608\n",
      "(20, 'tpe')\n",
      "100%|██████████| 20/20 [02:32<00:00,  7.61s/trial, best loss: -0.7999999999999999]\n",
      "F1-score: 0.888888888888889\n",
      "(50, 'tpe')\n",
      "100%|██████████| 50/50 [06:05<00:00,  7.31s/trial, best loss: -0.819672131147541] \n",
      "F1-score: 0.88268156424581\n",
      "(100, 'tpe')\n",
      " 15%|█▌        | 15/100 [01:32<08:44,  6.17s/trial, best loss: -0.7851851851851852]\n",
      "Interrupted.\n",
      "No model outperformed the baseline\n"
     ]
    }
   ],
   "source": [
    "datasets = X_train, X_test, y_train, y_test\n",
    "best, params, scores = optmimize(\n",
    "    datasets, f1_baseline, budget_list=[10, 20, 50, 100, 200, 500, 1000, 2000, 10000], \n",
    "    opt_method_list=['tpe'], use_cv=False\n",
    ")\n",
    "final_params.update(params)\n",
    "final_scores.update(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 'tpe')\n",
      "100%|██████████| 100/100 [15:33<00:00,  9.33s/trial, best loss: -0.819672131147541]\n",
      "F1-score: 0.88268156424581\n",
      "(200, 'tpe')\n",
      "100%|██████████| 200/200 [34:48<00:00, 10.44s/trial, best loss: -0.8153846153846154]\n",
      "F1-score: 0.8936170212765957\n",
      "F1 is better, but not statistically\n",
      "(500, 'tpe')\n",
      " 45%|████▌     | 225/500 [40:08<49:04, 10.71s/trial, best loss: -0.8153846153846154]  \n",
      "Interrupted.\n",
      "No model outperformed the baseline\n"
     ]
    }
   ],
   "source": [
    "datasets = X_train, X_test, y_train, y_test\n",
    "best, params, scores = optmimize(\n",
    "    datasets, f1_baseline, budget_list=[100, 200, 500, 1000, 2000, 10000], \n",
    "    opt_method_list=['tpe'], use_cv=False\n",
    ")\n",
    "final_params.update(params)\n",
    "final_scores.update(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 'tpe')\n",
      "100%|██████████| 500/500 [1:30:26<00:00, 10.85s/trial, best loss: -0.8292682926829268]\n",
      "F1-score: 0.8777777777777778\n",
      "(1000, 'tpe')\n",
      "100%|██████████| 1000/1000 [2:33:06<00:00,  9.19s/trial, best loss: -0.8292682926829268] \n",
      "F1-score: 0.8764044943820225\n",
      "(2000, 'tpe')\n",
      " 60%|█████▉    | 1198/2000 [3:18:57<2:13:11,  9.96s/trial, best loss: -0.8153846153846154]\n",
      "Interrupted.\n",
      "No model outperformed the baseline\n"
     ]
    }
   ],
   "source": [
    "datasets = X_train, X_test, y_train, y_test\n",
    "best, params, scores = optmimize(\n",
    "    datasets, f1_baseline, budget_list=[500, 1000, 2000, 10000], \n",
    "    opt_method_list=['tpe'], use_cv=False\n",
    ")\n",
    "final_params.update(params)\n",
    "final_scores.update(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({(10, 'tpe'): {'bootstrap': False,\n",
       "   'class_weight': 'balanced_subsample',\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 133,\n",
       "   'max_features': 0.9,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 3},\n",
       "  (20, 'tpe'): {'bootstrap': False,\n",
       "   'class_weight': 'balanced_subsample',\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 59,\n",
       "   'max_features': 0.9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3},\n",
       "  (50, 'tpe'): {'bootstrap': False,\n",
       "   'class_weight': 'balanced_subsample',\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 26,\n",
       "   'max_features': 0.9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2},\n",
       "  (100, 'tpe'): {'bootstrap': False,\n",
       "   'class_weight': 'balanced_subsample',\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 86,\n",
       "   'max_features': 0.9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2},\n",
       "  (200, 'tpe'): {'bootstrap': False,\n",
       "   'class_weight': 'balanced',\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 129,\n",
       "   'max_features': 0.9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2},\n",
       "  (500, 'tpe'): {'bootstrap': False,\n",
       "   'class_weight': 'balanced',\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 29,\n",
       "   'max_features': 0.9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2},\n",
       "  (1000, 'tpe'): {'bootstrap': False,\n",
       "   'class_weight': 'balanced',\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 21,\n",
       "   'max_features': 0.9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2}},\n",
       " {(10, 'tpe'): 0.8431372549019608,\n",
       "  (20, 'tpe'): 0.888888888888889,\n",
       "  (50, 'tpe'): 0.88268156424581,\n",
       "  (100, 'tpe'): 0.88268156424581,\n",
       "  (200, 'tpe'): 0.8936170212765957,\n",
       "  (500, 'tpe'): 0.8777777777777778,\n",
       "  (1000, 'tpe'): 0.8764044943820225})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_params, final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8936170212765957"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = final_params[(200, 'tpe')]\n",
    "\n",
    "clf = ExtraTreesClassifier(**params, random_state=42, n_jobs=-1).fit(X_train, y_train)\n",
    "y_pred_opt = clf.predict(X_test)\n",
    "metric = f1_score(y_test, y_pred_opt)\n",
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8913043478260869"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.contingency_tables import mcnemar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nr_correct_clf1</th>\n",
       "      <th>nr_incorrect_cl1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nr_correct_clf2</th>\n",
       "      <td>56940</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nr_incorrect_clf2</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  nr_correct_clf1 nr_incorrect_cl1\n",
       "nr_correct_clf2             56940                2\n",
       "nr_incorrect_clf2               2               18"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = ((y_pred_baseline == y_test) & (y_pred_opt == y_test)).sum()\n",
    "B = ((y_pred_baseline != y_test) & (y_pred_opt == y_test)).sum()\n",
    "C = ((y_pred_baseline == y_test) & (y_pred_opt != y_test)).sum()\n",
    "D = ((y_pred_baseline != y_test) & (y_pred_opt != y_test)).sum()\n",
    "\n",
    "contingency_table_df=pd.DataFrame(data={\"nr_correct_clf1\":[\"Yes/Yes\",\"No/Yes\"], \"nr_incorrect_cl1\":[\"Yes/No\",\"No/No\"]}, index=[\"nr_correct_clf2\",\"nr_incorrect_clf2\"])\n",
    "contingency_table_df.iloc[0,0]=A\n",
    "contingency_table_df.iloc[0,1]=B\n",
    "contingency_table_df.iloc[1,0]=C\n",
    "contingency_table_df.iloc[1,1]=D\n",
    "contingency_table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B + C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After calculating the Contingency Table, we need to define your hypothesis:\n",
    "*   H0: both models have the same performance\n",
    "*   H1: performances of the two models are not equal\n",
    "\n",
    "But we can't use McNemar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets compare on crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:37, 12.63s/it]\n",
      "3it [00:36, 12.18s/it]\n",
      "3it [00:33, 11.17s/it]\n",
      "3it [00:35, 11.93s/it]\n",
      "3it [00:35, 11.89s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "params_list = [final_params[(20, 'tpe')], final_params[(200, 'tpe')], {}]\n",
    "N_FOLDS: int = 5\n",
    "    \n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "results = np.zeros((len(params_list), N_FOLDS))\n",
    "cur_fold = 0\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train_cv, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train_cv, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    for i, params in tqdm(enumerate(params_list)):\n",
    "        clf = ExtraTreesClassifier(**params, random_state=42, n_jobs=-1).fit(X_train_cv, y_train_cv)\n",
    "        score = f1_score(y_val, clf.predict(X_val))\n",
    "        results[i, cur_fold] = score\n",
    "    cur_fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.896175</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.872340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.908108</td>\n",
       "      <td>0.896175</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.877005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.839779</td>\n",
       "      <td>0.887640</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.861878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4\n",
       "0  0.808511  0.896175  0.891304  0.864865  0.872340\n",
       "1  0.814815  0.908108  0.896175  0.864865  0.877005\n",
       "2  0.839779  0.887640  0.870056  0.853933  0.861878"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>r3</th>\n",
       "      <th>r4</th>\n",
       "      <th>r5</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    r1   r2   r3   r4   r5  mean\n",
       "0  3.0  2.0  2.0  1.5  2.0   2.1\n",
       "1  2.0  1.0  1.0  1.5  1.0   1.3\n",
       "2  1.0  3.0  3.0  3.0  3.0   2.6"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks = pd.DataFrame()\n",
    "ranks['r1'] = results.loc[:, 0].rank(ascending=False)\n",
    "ranks['r2'] = results.loc[:, 1].rank(ascending=False)\n",
    "ranks['r3'] = results.loc[:, 2].rank(ascending=False)\n",
    "ranks['r4'] = results.loc[:, 3].rank(ascending=False)\n",
    "ranks['r5'] = results.loc[:, 4].rank(ascending=False)\n",
    "ranks['mean'] = ranks.mean(axis=1)\n",
    "ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see the second configuration is better than others including baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'class_weight': 'balanced',\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 129,\n",
       " 'max_features': 0.9,\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 2}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_params[(200, 'tpe')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
