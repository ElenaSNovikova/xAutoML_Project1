{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hyperopt\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 6.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting py4j\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "\u001b[K     |████████████████████████████████| 200 kB 31.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: future in /Users/luzanikita/Software/anaconda3/lib/python3.8/site-packages (from hyperopt) (0.18.2)\n",
      "Requirement already satisfied: tqdm in /Users/luzanikita/Software/anaconda3/lib/python3.8/site-packages (from hyperopt) (4.47.0)\n",
      "Requirement already satisfied: cloudpickle in /Users/luzanikita/Software/anaconda3/lib/python3.8/site-packages (from hyperopt) (1.5.0)\n",
      "Requirement already satisfied: scipy in /Users/luzanikita/Software/anaconda3/lib/python3.8/site-packages (from hyperopt) (1.5.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /Users/luzanikita/Software/anaconda3/lib/python3.8/site-packages (from hyperopt) (2.4)\n",
      "Requirement already satisfied: six in /Users/luzanikita/Software/anaconda3/lib/python3.8/site-packages (from hyperopt) (1.15.0)\n",
      "Requirement already satisfied: numpy in /Users/luzanikita/Software/anaconda3/lib/python3.8/site-packages (from hyperopt) (1.19.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/luzanikita/Software/anaconda3/lib/python3.8/site-packages (from networkx>=2.2->hyperopt) (4.4.2)\n",
      "Installing collected packages: py4j, hyperopt\n",
      "Successfully installed hyperopt-0.2.7 py4j-0.10.9.7\n"
     ]
    }
   ],
   "source": [
    "! pip3 install  hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
    "RANDOM_SEED: int = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading train/test datasets and results df\n",
    "results_df_path = 'model_cmp.csv'\n",
    "df = pd.read_csv('data/winequality-red.csv')\n",
    "X, y = df.drop('quality', axis=1), df.quality > 5\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=RANDOM_SEED, test_size=.2, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8259587020648967"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_baseline = RandomForestClassifier(n_jobs=-1).fit(X_train, y_train)\n",
    "y_pred_baseline = clf_baseline.predict(X_test)\n",
    "f1_baseline = f1_score(y_test, y_pred_baseline)\n",
    "f1_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_cv(params):\n",
    "    f1_scores = []\n",
    "    for train_index, test_index in skf.split(X_train, y_train):\n",
    "        X_train_cv, X_val = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_cv, y_val = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        model = ExtraTreesClassifier(random_state=42, n_jobs=-1, **params).fit(X_train_cv, y_train_cv)\n",
    "        score = f1_score(y_val, model.predict(X_val))\n",
    "        f1_scores.append(score)\n",
    "    return {'loss': -np.mean(f1_scores), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_fast(params):\n",
    "    X_train_cv, X_val, y_train_cv, y_val =  train_test_split(X_train, y_train, test_size=.2, random_state=RANDOM_SEED)\n",
    "    model = ExtraTreesClassifier(random_state=42, n_jobs=-1, **params).fit(X_train_cv, y_train_cv)\n",
    "    score = f1_score(y_val, model.predict(X_val))\n",
    "    return {'loss': -score, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(search_space, budget:int = 10, use_cv: bool =True, method: str = 'random') -> float:\n",
    "    if use_cv:\n",
    "        objective = objective_cv\n",
    "    else:\n",
    "        objective = objective_fast\n",
    "    \n",
    "    if method == 'random':\n",
    "        method = rand.suggest\n",
    "    elif method == 'tpe':\n",
    "        method = tpe.suggest\n",
    "    \n",
    "    best_params = fmin(\n",
    "        fn=objective,\n",
    "        space=search_space,\n",
    "        algo=method,\n",
    "        max_evals=budget)\n",
    "    \n",
    "    return space_eval(search_space, best_params), objective(space_eval(search_space, best_params))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space={\n",
    "    'max_depth': hp.randint('max_depth', 1, 200),           \n",
    "    'min_samples_split':hp.randint('min_samples_split', 2, 5),   \n",
    "    'min_samples_leaf':hp.randint('min_samples_leaf', 1, 20),\n",
    "    'criterion':hp.choice('criterion', ['gini', 'entropy']),\n",
    "    'max_features':hp.choice('max_features', ['sqrt', 'log2', 0.9]),\n",
    "    'bootstrap':hp.choice('bootstrap', [True, False]),\n",
    "    \"class_weight\": hp.choice('class_weight', ['balanced', 'balanced_subsample'])\n",
    "}\n",
    "algorithm=tpe.suggest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.36trial/s, best loss: -0.8112449799196787]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'class_weight': 'balanced',\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 22,\n",
       " 'max_features': 0.9,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 4}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params, _ = run_experiment(search_space, 5, use_cv=False, method='tpe')\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7926829268292682"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = ExtraTreesClassifier(**params, random_state=42, n_jobs=-1).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optmimize(\n",
    "    datasets, f1_baseline, budget_list, opt_method_list,\n",
    "    use_cv=True, early_stopping=True\n",
    "):\n",
    "    X_train, X_test, y_train, y_test = datasets\n",
    "    final_params = {}\n",
    "    final_scores = {}\n",
    "    try:\n",
    "        for budget in budget_list:\n",
    "            for opt_method in opt_method_list:\n",
    "                print((budget, opt_method))\n",
    "                # tune model\n",
    "                params, _ = run_experiment(search_space, budget, use_cv=use_cv, method=opt_method)\n",
    "                final_params[(budget, opt_method)] = params\n",
    "\n",
    "                # evaluate model\n",
    "                clf = ExtraTreesClassifier(random_state=42, **params, n_jobs=-1).fit(X_train, y_train)\n",
    "                y_pred_opt = clf.predict(X_test)\n",
    "                f1 = f1_score(y_test, y_pred_opt)\n",
    "                final_scores[(budget, opt_method)] = f1\n",
    "                print(f\"F1-score: {f1}\")\n",
    "\n",
    "                # early stopping condition, because we are looking for the smallest time budget\n",
    "                if early_stopping and f1 > f1_baseline:\n",
    "                    A = ((y_pred_baseline == y_test) & (y_pred_opt == y_test)).sum()\n",
    "                    B = ((y_pred_baseline != y_test) & (y_pred_opt == y_test)).sum()\n",
    "                    C = ((y_pred_baseline == y_test) & (y_pred_opt != y_test)).sum()\n",
    "                    D = ((y_pred_baseline != y_test) & (y_pred_opt != y_test)).sum()\n",
    "                    result = mcnemar([[A, B], [C, D]])\n",
    "                    alpha = 0.05\n",
    "                    if B + C > 20 and result.pvalue < alpha:\n",
    "                        print(f\"Model with time budget {budget} and {opt_method} optimization algo beat the baseline!\")\n",
    "                        return (budget, opt_method), final_params, final_scores\n",
    "                    else:\n",
    "                        print(\"F1 is better, but not statistically\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted.\")\n",
    "        \n",
    "    print(\"No model outperformed the baseline\")\n",
    "    return None, final_params, final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_params = {}\n",
    "final_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 'tpe')\n",
      "100%|██████████| 10/10 [00:17<00:00,  1.76s/trial, best loss: -0.8161467853296603]\n",
      "F1-score: 0.8036253776435045\n",
      "(20, 'tpe')\n",
      "100%|██████████| 20/20 [00:23<00:00,  1.16s/trial, best loss: -0.8164002509750485]\n",
      "F1-score: 0.8221574344023324\n",
      "(50, 'tpe')\n",
      "100%|██████████| 50/50 [01:24<00:00,  1.70s/trial, best loss: -0.81801586794]     \n",
      "F1-score: 0.8214285714285714\n",
      "(100, 'tpe')\n",
      "100%|██████████| 100/100 [02:55<00:00,  1.75s/trial, best loss: -0.8215628574225663]\n",
      "F1-score: 0.8168168168168167\n",
      "(200, 'tpe')\n",
      "100%|██████████| 200/200 [05:36<00:00,  1.68s/trial, best loss: -0.82216029844896] \n",
      "F1-score: 0.8132530120481928\n",
      "(500, 'tpe')\n",
      " 26%|██▌       | 130/500 [03:52<11:00,  1.79s/trial, best loss: -0.8251873077524987]\n",
      "Interrupted.\n",
      "No model outperformed the baseline\n"
     ]
    }
   ],
   "source": [
    "datasets = X_train, X_test, y_train, y_test\n",
    "best, params, scores = optmimize(\n",
    "    datasets, f1_baseline, budget_list=[10, 20, 50, 100, 200, 500, 1000, 2000, 5000, 10000], \n",
    "    opt_method_list=['tpe'], use_cv=True)\n",
    "final_params.update(params)\n",
    "final_scores.update(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 'random')\n",
      "100%|██████████| 10/10 [00:18<00:00,  1.80s/trial, best loss: -0.82168574877736] \n",
      "F1-score: 0.8367952522255192\n",
      "F1 is better, but not statistically\n",
      "(20, 'random')\n",
      "100%|██████████| 20/20 [00:39<00:00,  1.97s/trial, best loss: -0.8197646891820621]\n",
      "F1-score: 0.8143712574850298\n",
      "(50, 'random')\n",
      "100%|██████████| 50/50 [01:30<00:00,  1.80s/trial, best loss: -0.81801586794]     \n",
      "F1-score: 0.8214285714285714\n",
      "(100, 'random')\n",
      "100%|██████████| 100/100 [02:57<00:00,  1.77s/trial, best loss: -0.8251873077524987]\n",
      "F1-score: 0.8245614035087719\n",
      "(200, 'random')\n",
      "100%|██████████| 200/200 [06:20<00:00,  1.90s/trial, best loss: -0.8251873077524987]\n",
      "F1-score: 0.8245614035087719\n",
      "(500, 'random')\n",
      "100%|██████████| 500/500 [16:16<00:00,  1.95s/trial, best loss: -0.82168574877736]  \n",
      "F1-score: 0.8367952522255192\n",
      "F1 is better, but not statistically\n",
      "(1000, 'random')\n",
      "  1%|          | 10/1000 [00:20<34:38,  2.10s/trial, best loss: -0.8251873077524987]\n",
      "Interrupted.\n",
      "No model outperformed the baseline\n"
     ]
    }
   ],
   "source": [
    "datasets = X_train, X_test, y_train, y_test\n",
    "best, params, scores = optmimize(\n",
    "    datasets, f1_baseline, budget_list=[10, 20, 50, 100, 200, 500, 1000, 2000, 5000, 10000], \n",
    "    opt_method_list=['random'], use_cv=True)\n",
    "final_params.update(params)\n",
    "final_scores.update(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space.update({\"n_estimators\": hp.randint('n_estimators', 50, 200)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 'random')\n",
      "100%|██████████| 1000/1000 [40:14<00:00,  2.41s/trial, best loss: -0.8257992774739824]\n",
      "F1-score: 0.8259587020648967\n",
      "(2000, 'random')\n",
      "100%|██████████| 2000/2000 [1:15:38<00:00,  2.27s/trial, best loss: -0.8277212997419445]\n",
      "F1-score: 0.813953488372093\n",
      "(5000, 'random')\n",
      "100%|██████████| 5000/5000 [3:03:21<00:00,  2.20s/trial, best loss: -0.8319567569242489]  \n",
      "F1-score: 0.8224852071005917\n",
      "(10000, 'random')\n",
      " 36%|███▌      | 3621/10000 [2:14:54<4:17:41,  2.42s/trial, best loss: -0.8281653094223579]"
     ]
    }
   ],
   "source": [
    "datasets = X_train, X_test, y_train, y_test\n",
    "best, params, scores = optmimize(\n",
    "    datasets, f1_baseline, budget_list=[1000, 2000, 5000, 10000], \n",
    "    opt_method_list=['random'], use_cv=True)\n",
    "final_params.update(params)\n",
    "final_scores.update(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({(10, 'tpe'): {'bootstrap': True,\n",
       "   'class_weight': 'balanced',\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 182,\n",
       "   'max_features': 0.9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4},\n",
       "  (20, 'tpe'): {'bootstrap': False,\n",
       "   'class_weight': 'balanced_subsample',\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 150,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 3},\n",
       "  (50, 'tpe'): {'bootstrap': False,\n",
       "   'class_weight': 'balanced',\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 94,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 4},\n",
       "  (100, 'tpe'): {'bootstrap': False,\n",
       "   'class_weight': 'balanced_subsample',\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 63,\n",
       "   'max_features': 0.9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3},\n",
       "  (200, 'tpe'): {'bootstrap': False,\n",
       "   'class_weight': 'balanced',\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4},\n",
       "  (10, 'random'): {'bootstrap': False,\n",
       "   'class_weight': 'balanced',\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 55,\n",
       "   'max_features': 0.9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2},\n",
       "  (20, 'random'): {'bootstrap': False,\n",
       "   'class_weight': 'balanced_subsample',\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 21,\n",
       "   'max_features': 0.9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2},\n",
       "  (50, 'random'): {'bootstrap': False,\n",
       "   'class_weight': 'balanced',\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 59,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 4},\n",
       "  (100, 'random'): {'bootstrap': False,\n",
       "   'class_weight': 'balanced_subsample',\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 120,\n",
       "   'max_features': 'log2',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2},\n",
       "  (200, 'random'): {'bootstrap': False,\n",
       "   'class_weight': 'balanced_subsample',\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 161,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2},\n",
       "  (500, 'random'): {'bootstrap': False,\n",
       "   'class_weight': 'balanced_subsample',\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 41,\n",
       "   'max_features': 0.9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2},\n",
       "  (1000, 'tpe'): {'bootstrap': True,\n",
       "   'class_weight': 'balanced',\n",
       "   'criterion': 'entropy',\n",
       "   'max_depth': 106,\n",
       "   'max_features': 0.9,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 50}},\n",
       " {(10, 'tpe'): 0.8036253776435045,\n",
       "  (20, 'tpe'): 0.8221574344023324,\n",
       "  (50, 'tpe'): 0.8214285714285714,\n",
       "  (100, 'tpe'): 0.8168168168168167,\n",
       "  (200, 'tpe'): 0.8132530120481928,\n",
       "  (10, 'random'): 0.8367952522255192,\n",
       "  (20, 'random'): 0.8143712574850298,\n",
       "  (50, 'random'): 0.8214285714285714,\n",
       "  (100, 'random'): 0.8245614035087719,\n",
       "  (200, 'random'): 0.8245614035087719,\n",
       "  (500, 'random'): 0.8367952522255192,\n",
       "  (1000, 'tpe'): 0.8298507462686566})"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_params, final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 'tpe')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8367952522255192"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = final_params[(500, 'random')]\n",
    "\n",
    "clf = ExtraTreesClassifier(**params, random_state=42, n_jobs=-1).fit(X_train, y_train)\n",
    "y_pred_opt = clf.predict(X_test)\n",
    "metric = f1_score(y_test, y_pred_opt)\n",
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8259587020648967"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.contingency_tables import mcnemar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = ((y_pred_baseline == y_test) & (y_pred_opt == y_test)).sum()\n",
    "B = ((y_pred_baseline != y_test) & (y_pred_opt == y_test)).sum()\n",
    "C = ((y_pred_baseline == y_test) & (y_pred_opt != y_test)).sum()\n",
    "D = ((y_pred_baseline != y_test) & (y_pred_opt != y_test)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B + C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After calculating the Contingency Table, we need to define your hypothesis:\n",
    "*   H0: both models have the same performance\n",
    "*   H1: performances of the two models are not equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pvalue      0.5034446716308595\n",
      "statistic   8.0\n",
      "Same proportions of errors (fail to reject H0)\n"
     ]
    }
   ],
   "source": [
    "result = mcnemar([[A, B], [C, D]])\n",
    "print(result)\n",
    "alpha = 0.05\n",
    "if result.pvalue > alpha:\n",
    "    print('Same proportions of errors (fail to reject H0)')\n",
    "else:\n",
    "    print('Different proportions of errors (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 'tpe')\n",
      "100%|██████████| 50/50 [00:42<00:00,  1.18trial/s, best loss: -0.8182954683370436]\n",
      "F1-score: 0.8106508875739645\n",
      "(50, 'random')\n",
      "100%|██████████| 50/50 [00:39<00:00,  1.26trial/s, best loss: -0.8181551423594746]\n",
      "F1-score: 0.8128654970760234\n",
      "(100, 'tpe')\n",
      "100%|██████████| 100/100 [01:19<00:00,  1.26trial/s, best loss: -0.8242742049458297]\n",
      "F1-score: 0.8163265306122449\n",
      "(100, 'random')\n",
      "100%|██████████| 100/100 [01:18<00:00,  1.27trial/s, best loss: -0.821152439674897]\n",
      "F1-score: 0.8173913043478261\n",
      "(200, 'tpe')\n",
      "100%|██████████| 200/200 [02:26<00:00,  1.37trial/s, best loss: -0.8215628574225663]\n",
      "F1-score: 0.8168168168168167\n",
      "(200, 'random')\n",
      " 12%|█▏        | 24/200 [00:19<02:22,  1.24trial/s, best loss: -0.8226465709588492]\n",
      "Interrupted.\n",
      "No model outperformed the baseline\n"
     ]
    }
   ],
   "source": [
    "datasets = X_train, X_test, y_train, y_test\n",
    "best, params, scores = optmimize(\n",
    "    datasets, f1_baseline, budget_list=[50, 100, 200, 500, 1000], \n",
    "    opt_method_list=['tpe', 'random'], use_cv=True, early_stopping=False\n",
    ")\n",
    "final_params.update(params)\n",
    "final_scores.update(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7552870090634441"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = final_params[(100, 'tpe')]\n",
    "\n",
    "clf = ExtraTreesClassifier(**params, random_state=42, n_jobs=-1).fit(X_train, y_train)\n",
    "y_pred_opt = clf.predict(X_test)\n",
    "metric = f1_score(y_test, y_pred_opt)\n",
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_baseline = ExtraTreesClassifier(n_jobs=-1).fit(X_train, y_train)\n",
    "y_pred_baseline = clf_baseline.predict(X_test)\n",
    "metric_baseline = f1_score(y_test, y_pred_baseline)\n",
    "metric_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = ((y_pred_baseline == y_test) & (y_pred_opt == y_test)).sum()\n",
    "B = ((y_pred_baseline != y_test) & (y_pred_opt == y_test)).sum()\n",
    "C = ((y_pred_baseline == y_test) & (y_pred_opt != y_test)).sum()\n",
    "D = ((y_pred_baseline != y_test) & (y_pred_opt != y_test)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pvalue      0.30175781250000017\n",
      "statistic   5.0\n",
      "Same proportions of errors (fail to reject H0)\n"
     ]
    }
   ],
   "source": [
    "result = mcnemar([[A, B], [C, D]])\n",
    "print(result)\n",
    "alpha = 0.05\n",
    "if result.pvalue > alpha:\n",
    "    print('Same proportions of errors (fail to reject H0)')\n",
    "else:\n",
    "    print('Different proportions of errors (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 'tpe')\n",
      "100%|██████████| 1000/1000 [02:22<00:00,  7.02trial/s, best loss: -0.6450645831778142]\n",
      "F1-score: 0.6384326229589381\n",
      "(1000, 'random')\n",
      "100%|██████████| 1000/1000 [02:28<00:00,  6.74trial/s, best loss: -0.6164660311392325]\n",
      "F1-score: 0.5561362129526444\n",
      "No model outperformed the baseline\n"
     ]
    }
   ],
   "source": [
    "datasets = X_train, X_test, y_train, y_test\n",
    "best, params, scores = optmimize(datasets, f1_baseline, budget_list=[1000], opt_method_list=['tpe', 'random'], use_cv=False)\n",
    "final_params.update(params)\n",
    "final_scores.update(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8255813953488372"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320,)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
